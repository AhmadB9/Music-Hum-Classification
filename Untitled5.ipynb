{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa5fd659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1035282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_spectrogram(spec):\n",
    "    # Normalize the spectrogram by subtracting the mean and dividing by the standard deviation\n",
    "    mean = np.mean(spec)\n",
    "    std = np.std(spec)\n",
    "    normalized_spec = (spec - mean) / std\n",
    "    return normalized_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba37f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_and_extract_spectrogram(audio_file,duration=5, n_mels=128, hop_length=512):\n",
    "\n",
    "    if not os.path.exists(audio_file):\n",
    "        print(f\"Error: File '{audio_file}' not found.\")\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            # Load audio file\n",
    "            y, sr = librosa.load(audio_file,duration=duration)\n",
    "\n",
    "            # Extract Mel spectrogram\n",
    "            mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, hop_length=hop_length)\n",
    "            \n",
    "          \n",
    "            # Convert to dB scale\n",
    "            mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "            #Normalize spectogram\n",
    "            norm_spectogram=normalize_spectrogram(mel_spectrogram_db)\n",
    "            # Transpose to have time steps as the first dimension (compatible with Conv1D input)\n",
    "            norm_spectogram = norm_spectogram.T\n",
    "\n",
    "            return norm_spectogram\n",
    "\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error encountered while processing '{audio_file}': {e}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "478cf824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Public filename</th>\n",
       "      <th>Interpreter</th>\n",
       "      <th>Song</th>\n",
       "      <th>Interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.wav</td>\n",
       "      <td>216</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Hum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Hum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002.wav</td>\n",
       "      <td>177</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Hum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003.wav</td>\n",
       "      <td>159</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Hum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.wav</td>\n",
       "      <td>160</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Whistle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Public filename  Interpreter    Song Interpretation\n",
       "0        0000.wav          216  Potter            Hum\n",
       "1        0001.wav          100  Potter            Hum\n",
       "2        0002.wav          177  Potter            Hum\n",
       "3        0003.wav          159  Potter            Hum\n",
       "4        0004.wav          160  Potter        Whistle"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the Excel file\n",
    "dataset= pd.read_csv('dataset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5db83dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6611it [00:00, 8329.48it/s] \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "### Now we iterate through every audio file and extract features\n",
    "### using Mel-Frequency Cepstral Coefficients\n",
    "audio_dataset_path='audio/'\n",
    "y_class=[]\n",
    "for index_num,row in tqdm(dataset.iterrows()):\n",
    "    y_class.append(row[\"Song\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y_class=to_categorical(labelencoder.fit_transform(y_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('model.keras',compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d3652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "def record_audio(output_file, duration=10, rate=44100, chunk=1024, format=pyaudio.paInt16, channels=2):\n",
    "    \"\"\"\n",
    "    Record audio from the default audio input device for a specified duration.\n",
    "    \n",
    "    Parameters:\n",
    "    - output_file: Output WAV file path where the recorded audio will be saved.\n",
    "    - duration: Duration of the recording in seconds (default is 10 seconds).\n",
    "    - rate: Sampling rate (samples/second).\n",
    "    - chunk: Number of frames per buffer.\n",
    "    - format: Audio sample format (e.g., pyaudio.paInt16).\n",
    "    - channels: Number of audio channels (1 for mono, 2 for stereo).\n",
    "    \"\"\"\n",
    "    audio = pyaudio.PyAudio()\n",
    "    \n",
    "    # Open stream\n",
    "    stream = audio.open(format=format,\n",
    "                        channels=channels,\n",
    "                        rate=rate,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=chunk)\n",
    "    \n",
    "    print(\"Recording...\")\n",
    "    \n",
    "    frames = []\n",
    "    \n",
    "    # Record audio in chunks and store in frames\n",
    "    for i in range(0, int(rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "    \n",
    "    print(\"Finished recording.\")\n",
    "    \n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    \n",
    "    # Save recorded audio to a WAV file\n",
    "    with wave.open(output_file, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(audio.get_sample_size(format))\n",
    "        wf.setframerate(rate)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    output_file = \"recorded_audio.wav\"\n",
    "    record_duration = 10  # seconds\n",
    "    \n",
    "    # Record audio and save to WAV file\n",
    "    record_audio(output_file, duration=record_duration)\n",
    "    \n",
    "    print(f\"Audio recorded and saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a232c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_spectogram=load_audio_and_extract_spectrogram('recorded_audio.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "921db2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_spectogram= np.expand_dims(test_spectogram, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33c7979a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Hakuna'], dtype='<U8')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_decoded = np.argmax(model.predict(np.array(test_spectogram)), axis=1)  # Get the index of the highest value in each row\n",
    "y_original = labelencoder.inverse_transform(y_decoded)\n",
    "y_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f8295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
